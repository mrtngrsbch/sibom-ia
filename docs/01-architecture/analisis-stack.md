# üìä An√°lisis del Stack y Problemas de Arquitectura

**Fecha:** 2026-01-15  
**Proyecto:** SIBOM Scraper Assistant  
**Analista:** OpenCode AI

---

## üìã 1. Stack Tecnol√≥gico Actual

### Frontend (Chatbot - Next.js)

**Tecnolog√≠as:**
- **Framework:** Next.js 16.1.1 (muy reciente, edge cases posibles)
- **React:** 19.0.0 (versi√≥n muy nueva, breaking changes)
- **TypeScript:** 5.0.0+
- **AI SDK:** Vercel AI SDK v4.1.0 + @ai-sdk/react v1.0.0
- **Styling:** Tailwind CSS 3.4.0
- **B√∫squeda:**
  - BM25 (keyword search) - implementaci√≥n propia
  - Vector Search (OpenAI embeddings + Qdrant)
  - SQL (sql.js - SQLite in-memory)
- **Testing:** Vitest 1.6.1 + React Testing Library

**Dependencias cr√≠ticas:**
```json
{
  "next": "16.1.1",           // ‚ö†Ô∏è Muy reciente
  "react": "^19.0.0",         // ‚ö†Ô∏è Versi√≥n muy nueva
  "ai": "^4.1.0",             // Vercel AI SDK
  "@ai-sdk/openai": "^1.0.0", // Cliente OpenRouter
  "openai": "^6.16.0",        // Cliente OpenAI (legacy)
  "qdrant-client": "^1.16.2" // Vector database
}
```

**Caracter√≠sticas:**
- RAG (Retrieval Augmented Generation) h√≠brido
- Streaming de respuestas en tiempo real
- B√∫squeda multi-modal: BM25 + Vector + SQL
- Sistema de filtros: municipio, tipo de norma, rango de fechas
- Caching agresivo multi-nivel
- Soporte para datos tabulares computacionales

---

### Backend (Python CLI - Scraper)

**Tecnolog√≠as:**
- **Python:** 3.13 (√∫ltima versi√≥n estable)
- **LLM Provider:** OpenRouter (multi-modelo)
- **Web Scraping:**
  - requests (HTTP client)
  - BeautifulSoup4 (HTML parsing)
  - lxml (XML/HTML r√°pido)
- **Procesamiento:**
  - Rich (TUI para progreso)
  - tqdm (barras de progreso)
  - python-dotenv (env vars)
- **Vector DB:** qdrant-client (opcional)
- **Data Export:** JSON + CSV + SQLite

**Dependencias:**
```
openai>=1.0.0
requests>=2.31.0
python-dotenv>=1.0.0
rich>=13.0.0
beautifulsoup4>=4.12.0
lxml>=4.9.0
qdrant-client>=1.7.0
tqdm>=4.66.0
```

**Caracter√≠sticas:**
- Scraping en 3 niveles: Listado ‚Üí Enlaces ‚Üí Texto completo
- Procesamiento paralelo configurable
- Paginaci√≥n autom√°tica detectada con BeautifulSoup
- Soporte para m√∫ltiples modelos LLM (gratis + premium)
- Indexado autom√°tico de normativas
- Generaci√≥n de CSV para an√°lisis de datos

---

### Arquitectura de Datos

**Fuentes de datos:**
1. **SIBOM Portal** (fuente externa)
   - URL base: https://sibom.slyt.gba.gob.ar
   - ~135 municipios de PBA
   - Boletines en HTML

2. **Python CLI Output** (backend)
   - JSON estructurados en `python-cli/boletines/`
   - √çndices en `python-cli/data/indices/`
   - SQLite DB en `python-cli/boletines/normativas.db`
   - CSV en `python-cli/boletines/csv/`

3. **Cloudflare R2** (producci√≥n)
   - Boletines JSON comprimidos con gzip (.gz)
   - √çndices JSON comprimidos
   - CDN global
   - 10 GB gratis, 10M requests/mes

4. **Qdrant** (vector search)
   - Embeddings OpenAI
   - B√∫squeda sem√°ntica
   - Deploy en Vercel (serverless)

---

## üö® 2. Problemas Cr√≠ticos de Arquitectura

### A. Monolito Frontend Sobrecargado

**Problema:**
El chatbot `/api/chat/route.ts` tiene 530 l√≠neas y hace TODO:
- Clasificaci√≥n de queries
- Filtrado autom√°tico
- Recuperaci√≥n de contexto (3 m√©todos: vector, BM25, SQL)
- Generaci√≥n de respuestas con streaming
- Manejo de off-topic y FAQ
- Comparaciones SQL directas
- Manejo de datos tabulares
- Logging extenso

**Consecuencias:**
- ‚ùå Dif√≠cil de mantener
- ‚ùå Dif√≠cil de testear
- ‚ùå Single Responsibility Principle violado
- ‚ùå Bug en un componente puede romper todo
- ‚ùå Dif√≠cil de escalar

**Impacto:** üî¥ **ALTO**

---

### B. Sistema de Caching Inconsistente

**Problema:**
Hay 3 niveles de cache sin coordinaci√≥n:

1. **Vercel Cache** (CDN):
```typescript
next: { revalidate: 3600 } // 1 hora
```

2. **In-memory cache** (Node.js):
```typescript
let indexCache: IndexEntry[] = [];
let normativasCache: NormativaIndexEntry[] = [];
const CACHE_DURATION = parseInt(process.env.INDEX_CACHE_DURATION || '300000'); // 5 min default
```

3. **File cache** (Map):
```typescript
const fileCache = new Map<string, FileCacheEntry>();
const FILE_CACHE_DURATION = 30 * 60 * 1000; // 30 minutos
```

**Problemas:**
- ‚ùå No hay invalidaci√≥n autom√°tica
- ‚ùå Cache in-memory no funciona en Vercel (serverless)
- ‚ùå Diferentes tiempos de expiraci√≥n (5 min, 30 min, 1 hora)
- ‚ùå No hay cache warming en deploy
- ‚ùå Cache in-memory se pierde en cada request (Vercel)
- ‚ùå No hay m√©tricas de cache hit/miss

**Impacto:** üî¥ **ALTO** - Causa inconsistencias entre dev y prod

---

### C. Dependencias Inestables

**Problema:**
Versiones muy nuevas con breaking changes:

```json
{
  "next": "16.1.1",      // üÜò Versi√≥n muy reciente (released hace 2 semanas)
  "react": "^19.0.0",    // üÜò RC/RC reciente
  "ai": "^4.1.0"         // Vercel AI SDK en desarrollo activo
}
```

**Consecuencias:**
- ‚ö†Ô∏è Breaking changes constantes
- ‚ö†Ô∏è Bug reports en GitHub
- ‚ö†Ô∏è Poca documentaci√≥n estable
- ‚ö†Ô∏è Compatibilidad incierta con otras librer√≠as

**Impacto:** üü° **MEDIO** - Riesgo de regresiones

---

### D. Gesti√≥n de Estado React Inexistente

**Problema:**
No hay state management global (Zustand, Redux, Jotai, Context API robusto).

**Estado actual:**
- Solo `ThemeContext.tsx` para dark mode
- Estado del chat en componentes individuales
- Props drilling para filtros
- No hay store global para:
  - Historial de queries
  - Filtros persistentes
  - Estado del usuario
  - Preferencias

**Consecuencias:**
- ‚ùå Props drilling excesivo
- ‚ùå Estado fr√°gil entre navegaciones
- ‚ùå No hay persistencia de filtros
- ‚ùå No hay undo/redo en queries
- ‚ùå Dif√≠cil implementar features complejas

**Impacto:** üü° **MEDIO** - Escalabilidad limitada

---

### E. Testing Incompleto

**Problema:**
Cobertura de tests baja:

**Tests existentes:**
```
chatbot/src/lib/rag/__tests__/table-formatter.test.ts
chatbot/src/lib/computation/__tests__/table-engine.test.ts
chatbot/src/lib/computation/__tests__/query-parser.test.ts
chatbot/src/tests/unit/test-query-analyzer.ts
chatbot/src/tests/unit/query-classifier-semantic.test.ts
chatbot/src/tests/unit/test-filter-extraction.ts
```

**Faltan tests cr√≠ticos:**
- ‚ùå Tests de integraci√≥n de `/api/chat`
- ‚ùå Tests de streaming
- ‚ùå Tests de RAG (mock vector search)
- ‚ùå Tests de SQL retriever
- ‚ùå Tests de componentes UI
- ‚ùå E2E tests (Playwright/Cypress)
- ‚ùå Tests de carga/performance

**Impacto:** üü° **MEDIO** - Riesgo de bugs en producci√≥n

---

### F. Configuraci√≥n de TypeScript Relajada

**Problema:**
```json
{
  "compilerOptions": {
    "strict": true,
    "skipLibCheck": true,     // ‚ö†Ô∏è Salta verificaci√≥n de types de libs
    "allowJs": true,           // ‚ö†Ô∏è Permite JS sin types
    "noEmit": true,            // ‚ö†Ô∏è No genera archivos de declaraci√≥n
  }
}
```

**Consecuencias:**
- ‚ö†Ô∏è Errores de types en runtime
- ‚ö†Ô∏è Malas pr√°cticas se propagan
- ‚ö†Ô∏è Dif√≠cil refactorizar

**Impacto:** üü¢ **BAJO** - Manejable con buenas pr√°cticas

---

### G. Python CLI Fuera de Producci√≥n

**Problema:**
El scraper Python CLI solo corre localmente:

**Estado actual:**
```bash
cd python-cli
source venv/bin/activate
python3 sibom_scraper.py --limit 5
```

**Problemas:**
- ‚ùå No hay servicio de scraping automatizado en la nube
- ‚ùå No hay cron jobs o scheduled jobs
- ‚ùå Solo hay un workflow GitHub Actions (`automated-scraping.yml`)
- ‚ùå No hay retries autom√°ticos
- ‚ùå No hay monitoreo de fallas
- ‚ùå No hay alertas

**Impacto:** üü° **MEDIO** - Scraping manual necesario

---

## üè≠ 3. Problemas de Producci√≥n

### A. Deployment Manual de Datos

**Problema:**
Los datos NO se suben autom√°ticamente a Cloudflare R2:

**Proceso actual (manual):**
```bash
cd python-cli
python3 compress_for_r2.py
# Subir manualmente al dashboard de Cloudflare O
wrangler r2 bucket create sibom-data
./upload_to_r2.sh
```

**Problemas:**
- ‚ùå Proceso manual propenso a errores
- ‚ùå No hay automatizaci√≥n
- ‚ùå No hay versionado de datos
- ‚ùå No hay rollback de datos
- ‚ùå No hay validaci√≥n post-upload

**Impacto:** üî¥ **ALTO** - Deployment fr√°gil

---

### B. Variables de Entorno Inconsistentes

**Problema:**
Variables de entorno difieren entre envs:

**Local (`.env.local`):**
```env
OPENROUTER_API_KEY=xxxxxx
OPENROUTER_MODEL=google/gemini-3-flash-preview
```

**Production (Vercel):**
```env
OPENROUTER_API_KEY=...
LLM_MODEL_PRIMARY=anthropic/claude-3.5-sonnet
LLM_MODEL_ECONOMIC=google/gemini-flash-1.5
GITHUB_DATA_REPO=pub-xxxxx.r2.dev/sibom-data
GITHUB_DATA_BRANCH=
GITHUB_USE_GZIP=true
USE_NORMATIVAS_INDEX=true
INDEX_CACHE_DURATION=3600000
```

**Problemas:**
- ‚ùå Nombres de variables diferentes
- ‚ùå Modelos LLM diferentes entre envs
- ‚ùå No hay validaci√≥n de env vars
- ‚ùå No hay valores por defecto consistentes
- ‚ùå No hay manejo de missing vars

**Impacto:** üî¥ **ALTO** - Bugs de configuraci√≥n

---

### C. Monitoreo y Logging Insuficiente

**Problema:**
Logging actual: `console.log()` en producci√≥n

**Estado actual:**
```typescript
console.log('[ChatAPI] Nueva petici√≥n recibida');
console.log(`[ChatAPI] √çndice cargado: ${indexCache.length} documentos`);
```

**Faltan:**
- ‚ùå Structured logging (JSON logs)
- ‚ùå Error tracking (Sentry, LogRocket)
- ‚ùå Performance monitoring
- ‚ùå Analytics de queries (qu√© buscan los usuarios)
- ‚ùå Cost tracking de LLMs
- ‚ùå Alertas autom√°ticas
- ‚ùå Dashboards de m√©tricas

**Impacto:** üü° **MEDIO** - Dif√≠cil debug en producci√≥n

---

### D. No hay CI/CD Completo

**Problema:**
GitHub Actions solo tiene 1 workflow:

**Existente:**
```yaml
# .github/workflows/automated-scraping.yml
# Solo para scraping automatizado
```

**Faltan:**
- ‚ùå CI tests on push
- ‚ùå Lint checks
- ‚ùå Type checking
- ‚ùå Build verification
- ‚ùå E2E tests
- ‚ùå Security scans (Dependabot, Snyk)
- ‚ùå Deployment autom√°tico a staging
- ‚ùå Canary deployments

**Impacto:** üü° **MEDIO** - Bugs llegan a producci√≥n

---

### E. Scalability Issues

**Problema:**
Arquitectura no escala bien:

**Bottlenecks:**
1. **RAG system:**
   - BM25 se reconstruye en cada request (NO cacheado)
   - No hay pre-computation de √≠ndices
   - No hay rate limiting de LLM calls

2. **SQL retrieval:**
   - `sql.js` corre en browser/server (in-memory)
   - No hay database connection pooling
   - SQLite no escala para queries complejas

3. **Vector search:**
   - Qdrant no est√° optimizado
   - No hay dimensionality reduction
   - No hay approximate nearest neighbors

**Impacto:** üü° **MEDIO** - Performance degrada con tr√°fico

---

### F. Security Issues

**Problema:**
No hay security best practices:

**Faltan:**
- ‚ùå Rate limiting en `/api/chat`
- ‚ùå Input sanitization robusta
- ‚ùå API key rotation
- ‚ùå CORS policies estrictas
- ‚ùå CSP headers
- ‚ùå Helmet.js (security headers)
- ‚ùå SQL injection prevention
- ‚ùå XSS prevention
- ‚ùå Dependency vulnerability scanning

**Impacto:** üî¥ **ALTO** - Riesgo de seguridad

---

### G. Cost Management

**Problema:**
No hay tracking de costos:

**Costos actuales:**
- Vercel: Gratis (hasta 100 GB/mes)
- Cloudflare R2: Gratis (hasta 10 GB, 10M requests)
- OpenRouter: Uso real de LLMs (~$0.017/query)

**Faltan:**
- ‚ùå Token usage tracking
- ‚ùå Cost forecasting
- ‚ùå Budget alerts
- ‚ùå Cost optimization
- ‚ùå Usage analytics (queries por usuario)

**Impacto:** üü° **MEDIO** - Costos pueden explotar

---

## üìä 4. Resumen de Problemas por Severidad

### üî¥ CR√çTICO (Resolver YA)
1. **Deployment manual de datos** - Riesgo de errores humanos
2. **Variables de entorno inconsistentes** - Bugs en producci√≥n
3. **Security issues** - Vulnerabilidades de seguridad

### üü° ALTO (Resolver pronto)
1. **Monolito frontend sobrecargado** - Dif√≠cil mantener
2. **Sistema de caching inconsistente** - Bugs entre envs
3. **Monitoreo insuficiente** - Dif√≠cil debug en prod
4. **Scalability issues** - Performance degrada

### üü¢ MEDIO (Resolver cuando sea posible)
1. **Testing incompleto** - Riesgo de bugs
2. **Dependencias inestables** - Breaking changes
3. **Gesti√≥n de estado inexistente** - UX limitada
4. **Python CLI fuera de producci√≥n** - Scraping manual
5. **CI/CD incompleto** - Bugs llegan a prod
6. **Cost management** - Costos impredecibles

---

## üéØ 5. Recomendaciones Prioritarias

### Fase 1: Estabilizaci√≥n (1-2 semanas)

**Objetivo:** Hacer el deployment confiable

1. **Automatizar deployment de datos**
   ```bash
   # Script: deploy_data.sh
   - Comprimir datos
   - Subir a R2 autom√°ticamente
   - Validar post-upload
   - Versionar datos (rollback)
   ```

2. **Unificar variables de entorno**
   ```typescript
   // src/lib/config.ts
   export const config = {
     openRouterApiKey: env.OPENROUTER_API_KEY,
     llmModelPrimary: env.LLM_MODEL_PRIMARY || 'anthropic/claude-3.5-sonnet',
     // ...
   }
   ```

3. **Security b√°sica**
   ```typescript
   // middleware.ts
   - Rate limiting (/api/chat)
   - Helmet.js (headers)
   - CORS policies
   - Input sanitization
   ```

### Fase 2: Monitoreo y Observabilidad (2-3 semanas)

**Objetivo:** Visibilidad total de producci√≥n

1. **Structured logging**
   ```typescript
   import pino from 'pino';
   const logger = pino({ level: 'info' });
   logger.info({ query, model, tokens }, 'Chat query processed');
   ```

2. **Error tracking**
   ```typescript
   import * as Sentry from '@sentry/nextjs';
   Sentry.init({ dsn: process.env.SENTRY_DSN });
   ```

3. **Analytics**
   ```typescript
   // Track queries, costs, performance
   analytics.track('chat_query', { model, tokens, latency });
   ```

### Fase 3: Refactorizaci√≥n (3-4 semanas)

**Objetivo:** Mejorar mantenibilidad

1. **Separar responsabilidades**
   ```
   /api/chat/route.ts (orquestador)
   /api/chat/classify.ts
   /api/chat/retrieve.ts
   /api/chat/generate.ts
   /api/chat/filters.ts
   ```

2. **Testing coverage**
   ```typescript
   // unit tests, integration tests, E2E tests
   // target: 80% coverage
   ```

3. **State management**
   ```typescript
   // Zustand store global
   // Filtros persistentes
   // Historial de queries
   ```

### Fase 4: Optimizaci√≥n (2-3 semanas)

**Objetivo:** Mejorar performance y costos

1. **Cache inteligente**
   ```typescript
   // Redis / Vercel KV
   // Cache warming en deploy
   // Cache invalidation autom√°tica
   ```

2. **Pre-computation**
   ```typescript
   // BM25 pre-computado
   // Vector indexes pre-construidos
   // SQL indexes
   ```

3. **Rate limiting de LLMs**
   ```typescript
   // Cache responses similares
   // Batch queries
   // Token optimization
   ```

---

## üìà 6. M√©tricas de √âxito

**Objetivos:**

| M√©trica                      | Actual       | Objetivo | Deadline  |
| ---------------------------- | ------------ | -------- | --------- |
| Deployment success rate      | 70%          | 99%      | 2 semanas |
| Mean Time to Recovery (MTTR) | 4h           | 30 min   | 4 semanas |
| Test coverage                | ~30%         | 80%      | 6 semanas |
| API response time (p95)      | 5s           | 2s       | 4 semanas |
| Cost per 1000 queries        | ~$17         | <$10     | 6 semanas |
| Uptime                       | 95%          | 99.9%    | 2 semanas |
| Security vulnerabilities     | 2 (med/baja) | 0        | 2 semanas |

---

## üöÄ 7. Conclusi√≥n

**Estado actual:**
- ‚úÖ Scraping funciona bien (Python CLI)
- ‚ö†Ô∏è Frontend funcional pero fr√°gil
- ‚ùå Producci√≥n no est√° lista
- ‚ùå Arquitectura necesita refactorizaci√≥n
- ‚ùå Monitoreo insuficiente

**Pr√≥ximos pasos:**
1. Automatizar deployment de datos
2. Unificar variables de entorno
3. Implementar security b√°sica
4. Refactorizar monolito frontend
5. A√±adir monitoreo completo
6. Aumentar test coverage

**Tiempo estimado:** 8-12 semanas para producci√≥n robusta

---

**Generado por:** OpenCode AI  
**Fecha:** 2026-01-15  
**Versi√≥n:** 1.0.0
